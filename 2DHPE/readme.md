# 2D HPE paper list
## 2D HPE from monocular RGB images and videos
### -single-person 2D HPE
Deeppose: Human pose estimationvia deep neural networks (CVPR2014) [[Paper](https://arxiv.org/pdf/1312.4659.pdf)]

Articulated pose estimation by a graphical model with image dependent pairwise relations (NIPS2014) [[Paper](https://papers.nips.cc/paper/2014/file/8b6dd7db9af49e67306feb59a8bdc52c-Paper.pdf)]

Deep Convolutional Neural Networks for Efficient Pose Estimation in Gesture Videos (ACCV2014) [[Paper](https://www.robots.ox.ac.uk/~vgg/publications/2014/Pfister14a/pfister14a.pdf)]

Stacked hourglass networks forhuman pose estimation (ECCV2016) [[paper](https://arxiv.org/pdf/1603.06937.pdf)]

Efficient object localization using convolutional networks (CVPR2015) [[paper](https://arxiv.org/pdf/1411.4280.pdf)]

Human pose estimation with iterative error feedback (CVPR2016) [[paper](https://arxiv.org/pdf/1507.06550.pdf)]

Compositional humanpose regression (ICCV2017) [[paper](https://arxiv.org/pdf/1704.00159.pdf)]

Human pose regressionby combining indirect part detection and contextual information (Computers & Graphics 2019) [[paper](https://arxiv.org/pdf/1710.02322.pdf)]

Numerical coordinate regression with convolutional neural networks (arXiv) [[paper](https://arxiv.org/pdf/1801.07372.pdf)]

Heterogeneous multi-tasklearning for human pose estimation with deep convolutionalneural network (CVPR2014 Workshops) [[paper](https://arxiv.org/pdf/1406.3474.pdf)]

Combining local appear-ance and holistic view: Dual-source deep neural networks for human pose estimation (CVPR2015) [[paper](https://arxiv.org/pdf/1504.07159.pdf)]

2d/3d pose estimationand action recognition using multitask deep learning (CVPR2018) [[paper](https://arxiv.org/pdf/1802.09232.pdf)]

Fast human pose estimation (CVPR2019) [[paper](https://arxiv.org/pdf/1811.05419.pdf)][[code](https://github.com/ilovepose/fast-human-pose-estimation.pytorch)]

Joint training of a convolutional network and a graphical model for human pose estimation (Advances in Neural Information Processing Systems 2014) [[paper](https://arxiv.org/pdf/1406.2984.pdf)]

Pose machines: Articulated pose estimation via inference machines (ECCV2014) [[paper](https://link.springer.com/content/pdf/10.1007/978-3-319-10605-2_3.pdf)]

Convolutional pose machines (CVPR2016) [[paper](https://arxiv.org/pdf/1602.00134.pdf)][[code](https://github.com/CMU-Perceptual-Computing-Lab/convolutional-pose-machines-release)]

Human pose estimationusing deep consensus voting (ECCV 2016) [[paper](https://arxiv.org/pdf/1603.08212.pdf)]

Human pose estimation via convolutional part heatmap regression (ECCV2016) [[paper](https://arxiv.org/pdf/1609.01743.pdf)][[code](https://github.com/1adrianb/human-pose-estimation)]

Chained predictions using convolutional neural networks (ECCV2016) [[paper](https://arxiv.org/pdf/1605.02346.pdf)]

Recurrent human pose estimation (FG2017) [[paper](https://arxiv.org/pdf/1605.02914.pdf)]

Learning feature pyramids for human pose estimation (ICCV2017) [[paper](https://arxiv.org/pdf/1708.01101.pdf)][[code](https://github.com/bearpaw/PyraNet)]

Lstm pose machines (CVPR2018) [[paper](https://arxiv.org/pdf/1712.06316.pdf)][[code](https://github.com/lawy623/LSTM_Pose_Machines)]

Adapting mobilenets for mobile based upper body pose estimation (AVSS2018) [[paper](https://research.edgehill.ac.uk/ws/files/20126254/adapting-mobilenets-debnath.pdf)]

Human pose estimation with spatial contextual information (arXiv) [[paper](https://arxiv.org/pdf/1901.01760.pdf)]

Unipose: Unified human pose estimation in single images and videos (CVPR2020) [[paper](https://arxiv.org/pdf/2001.08095.pdf)]

Multi-context attention for human pose estimation (CVPR2017) [[paper](https://arxiv.org/pdf/1702.07432.pdf)]

Adversarialposenet: A structure-aware convolutional network for human pose estimation (ICCV 2017) [[paper](https://arxiv.org/pdf/1705.00389.pdf)]

Self adversarial trainingfor human pose estimation(Asia-Pacific Signal and InformationProcessing Association Annual Summit and Conference2018) [[paper](https://arxiv.org/pdf/1707.02439.pdf)]

Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation (CVPR2018) [[paper](https://arxiv.org/pdf/1805.09707.pdf)]

End-to-end learning of deformable mixture of parts and deep convolutional neuralnetworks for human pose estimation (CVPR2016) [[paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/Yang_End-To-End_Learning_of_CVPR_2016_paper.pdf)]

Structured feature learning for pose estimation (CVPR2016) [[paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/Chu_Structured_Feature_Learning_CVPR_2016_paper.pdf)]

Multi-scale structure-aware network for human pose estimation (ECCV2018) [[paper](https://arxiv.org/pdf/1803.09894.pdf)]

Deeply learned compositional models for human pose estimation (ECCV2018) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Tang_Deeply_Learned_Compositional_ECCV_2018_paper.pdf)]

Does learning specific features for relatedparts help human pose estimation? (CVPR2019) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_Does_Learning_Specific_Features_for_Related_Parts_Help_Human_Pose_CVPR_2019_paper.pdf)]

Modeep:  Adeep learning framework using motion features for human pose estimation (ACCV2014) [[paper](https://arxiv.org/pdf/1409.7963.pdf)]

Flowing convnets for human pose estimation in videos (ICCV2015) [[paper](https://openaccess.thecvf.com/content_iccv_2015/papers/Pfister_Flowing_ConvNets_for_ICCV_2015_paper.pdf)]

Key frame proposal network for efficient pose estimation in videos (ECCV2020) [[paper](https://arxiv.org/pdf/2007.15217.pdf)][code(https://github.com/Yuexiaoxi10/Key-Frame-Proposal-Network-for-Efficient-Pose-Estimation-in-Videos)]

### -multi-person 2D HPE
Simple baselines for human poseestimation and tracking (ECCV2018) [[paper](https://arxiv.org/pdf/1804.06208.pdf)][[code](https://github.com/Microsoft/human-pose-estimation.pytorch)]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]

123 () [[paper]()]


